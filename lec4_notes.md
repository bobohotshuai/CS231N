# Lecture 4: Convolutional Neural Networks (å·ç§¯ç¥ç»ç½‘ç»œ)



## ä¸»è¦å†…å®¹

### 1. ä¼ ç»Ÿç¥ç»ç½‘ç»œçš„é—®é¢˜

![Last Time: Neural Networks](lec4-1.jpg)
![Today: Convolutional Networks](lec4-3.jpg)

#### å…¨è¿æ¥å±‚çš„å±€é™æ€§

**çº¿æ€§è¯„åˆ†å‡½æ•°ï¼š**
$$f = Wx$$

**2å±‚ç¥ç»ç½‘ç»œï¼š**
$$f = W_2 \max(0, W_1 x)$$

**æ ¸å¿ƒé—®é¢˜ï¼šå›¾åƒçš„ç©ºé—´ç»“æ„è¢«ç ´åï¼**

**ç¤ºä¾‹åˆ†æï¼š**
- è¾“å…¥å›¾åƒï¼š32Ã—32Ã—3 = **3072 ç»´å‘é‡**
- ç¬¬ä¸€å±‚éšè—å±‚ï¼š100 ä¸ªç¥ç»å…ƒ
- è¾“å‡ºå±‚ï¼š10 ä¸ªç±»åˆ«

å½“å›¾åƒè¢«å±•å¹³æˆä¸€ç»´å‘é‡æ—¶ï¼Œç›¸é‚»åƒç´ çš„ç©ºé—´å…³ç³»å®Œå…¨ä¸¢å¤±ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸åŒç±»åˆ«çš„å›¾åƒåœ¨å±•å¹³åå˜å¾—éš¾ä»¥åŒºåˆ†ã€‚

---

### 2. å›¾åƒç‰¹å¾ vs. å·ç§¯ç½‘ç»œ

![Image features vs. ConvNets](lec4-2.jpg)

#### ä¸¤ç§å¤„ç†å›¾åƒçš„èŒƒå¼

**ä¼ ç»Ÿæ–¹æ³•ï¼šç‰¹å¾æå–**
```
å›¾åƒ â†’ ç‰¹å¾æå– â†’ ç‰¹å¾å‘é‡ f â†’ 10ä¸ªç±»åˆ«åˆ†æ•°
                                    â†‘
                                  è®­ç»ƒ
```
- æ‰‹å·¥è®¾è®¡ç‰¹å¾ï¼ˆHOGã€SIFT ç­‰ï¼‰
- ç‰¹å¾å›ºå®šä¸å˜

**å·ç§¯ç½‘ç»œæ–¹æ³•ï¼šç«¯åˆ°ç«¯å­¦ä¹ **
```
å›¾åƒ â†’ [CONV-POOLå±‚å †å ] â†’ 10ä¸ªç±»åˆ«åˆ†æ•°
                           â†‘
                         è®­ç»ƒ
```
- è‡ªåŠ¨å­¦ä¹ ç‰¹å¾å±‚æ¬¡ç»“æ„
- ç‰¹å¾å¯è®­ç»ƒ

**å¼•ç”¨ï¼š** Krizhevsky, Sutskever, and Hinton, "Imagenet classification with deep convolutional neural networks", NIPS 2012.

---

### 3. å·ç§¯ç½‘ç»œçš„åŸºæœ¬ç»„ä»¶




#### å››å¤§æ ¸å¿ƒç»„ä»¶

1. **å…¨è¿æ¥å±‚ (Fully-Connected Layer)**
   - å·²ç»å­¦è¿‡çš„ä¼ ç»Ÿç¥ç»ç½‘ç»œå±‚
   - å…¬å¼ï¼š$s = Wx + b$

2. **æ¿€æ´»å‡½æ•° (Activation Function)**
   - ReLUã€Sigmoidã€Tanh ç­‰
   - å¼•å…¥éçº¿æ€§

3. **å·ç§¯å±‚ (Convolution Layer)** â­
   - å›¾åƒç‰¹å®šçš„æ“ä½œ
   - ä¿ç•™ç©ºé—´ç»“æ„

4. **æ± åŒ–å±‚ (Pooling Layer)** â­
   - é™é‡‡æ ·æ“ä½œ
   - å‡å°‘ç©ºé—´ç»´åº¦

---

### 4. å·ç§¯å±‚è¯¦è§£

#### 4.1 å·ç§¯å±‚çš„å·¥ä½œåŸç†

![Convolution Layer - Basic](lec4-6.jpg)

**ç¤ºä¾‹ï¼š**
- è¾“å…¥ï¼š3Ã—32Ã—32 å›¾åƒï¼ˆ3ä¸ªé€šé“ï¼Œ32Ã—32ç©ºé—´å¤§å°ï¼‰
- ä½¿ç”¨ 6 ä¸ª 3Ã—5Ã—5 çš„æ»¤æ³¢å™¨
- è¾“å‡ºï¼š6 ä¸ªæ¿€æ´»å›¾ï¼Œæ¯ä¸ª 1Ã—28Ã—28

**å…³é”®è¿‡ç¨‹ï¼š**
1. 6ä¸ªæ»¤æ³¢å™¨ï¼ˆæ¯ä¸ª 3Ã—5Ã—5ï¼‰åœ¨è¾“å…¥ä¸Šæ»‘åŠ¨
2. æ¯ä¸ªæ»¤æ³¢å™¨äº§ç”Ÿä¸€ä¸ªæ¿€æ´»å›¾
3. å †å æ¿€æ´»å›¾å¾—åˆ° 6Ã—28Ã—28 çš„è¾“å‡º

#### 4.2 å•ä¸ªå·ç§¯æ“ä½œ

![Convolution Layer - Detail](lec4-5.jpg)

**è®¡ç®—ç»†èŠ‚ï¼š**
- è¾“å…¥ï¼š32Ã—32Ã—3 å›¾åƒ
- æ»¤æ³¢å™¨ï¼š5Ã—5Ã—3ï¼ˆw æƒé‡çŸ©é˜µï¼‰
- è®¡ç®—ï¼šæå– 5Ã—5Ã—3 çš„å°å—ï¼Œä¸æ»¤æ³¢å™¨åšç‚¹ç§¯

**å…¬å¼ï¼š**
$$\text{1 ä¸ªæ•°å€¼} = w^T x + b$$

å…¶ä¸­ï¼š
- $x$ï¼š5Ã—5Ã—3 = 75ç»´çš„å›¾åƒå—
- $w$ï¼šæ»¤æ³¢å™¨æƒé‡ï¼ˆ75ç»´ï¼‰
- $b$ï¼šåç½®é¡¹
- ç»“æœï¼š1ä¸ªæ•°å€¼ï¼ˆç‚¹ç§¯ + åç½®ï¼‰

---

### 5. å·ç§¯æ“ä½œçš„å‚æ•°é…ç½®

#### 5.1 å·ç§¯å±‚æ€»ç»“

![Convolution summary](lec4-12.jpg)


**è¾“å…¥è§„æ ¼ï¼š**
- Input: $C_{in} \times H \times W$

**è¶…å‚æ•° (Hyperparameters)ï¼š**
1. **Kernel size (æ»¤æ³¢å™¨å¤§å°)**ï¼š$K_H \times K_W$
2. **Number of filters (æ»¤æ³¢å™¨æ•°é‡)**ï¼š$C_{out}$
3. **Padding (å¡«å……)**ï¼šP
4. **Stride (æ­¥é•¿)**ï¼šS

**æƒé‡çŸ©é˜µï¼š**
- Weight matrix: $C_{out} \times C_{in} \times K_H \times K_W$
- åŒ…å« $C_{out}$ ä¸ªæ»¤æ³¢å™¨ï¼Œæ¯ä¸ªå¤§å°ä¸º $C_{in} \times K_H \times K_W$

**åç½®å‘é‡ï¼š**
- Bias vector: $C_{out}$

**è¾“å‡ºå¤§å°ï¼š**
$$H' = \frac{H - K + 2P}{S} + 1$$
$$W' = \frac{W - K + 2P}{S} + 1$$
- Output size: $C_{out} \times H' \times W'$

#### 5.2 å¸¸ç”¨é…ç½®

**Common settings (å¸¸è§é…ç½®)ï¼š**

1. **å°æ–¹å½¢æ»¤æ³¢å™¨**
   - $K_H = K_W$ï¼ˆæ­£æ–¹å½¢æ»¤æ³¢å™¨ï¼‰
   - $P = (K-1)/2$ï¼ˆ"Same" paddingï¼Œä¿æŒå°ºå¯¸ï¼‰

2. **é€šé“æ•°é…ç½®**
   - $C_{in}, C_{out} = 32, 64, 128, 256$ï¼ˆ2çš„å¹‚æ¬¡ï¼‰

3. **3Ã—3 å·ç§¯**
   - $K=3, P=1, S=1$ï¼ˆæœ€å¸¸ç”¨ï¼‰

4. **5Ã—5 å·ç§¯**
   - $K=5, P=2, S=1$

5. **1Ã—1 å·ç§¯**
   - $K=1, P=0, S=1$ï¼ˆé€šé“é—´äº¤äº’ï¼‰

6. **é™é‡‡æ ·å·ç§¯**
   - $K=3, P=1, S=2$ï¼ˆä¸‹é‡‡æ · 2å€ï¼‰

---

### 6. Strideï¼ˆæ­¥é•¿ï¼‰è¯¦è§£

![Strided Convolution](lec4-11.jpg)

**æ­¥é•¿ç¤ºä¾‹ï¼š**

```
è¾“å…¥ï¼š7Ã—7
æ»¤æ³¢å™¨ï¼š3Ã—3
æ­¥é•¿ï¼š2
è¾“å‡ºï¼š3Ã—3
```

**é€šç”¨å…¬å¼ï¼š**
- Input: W
- Filter: K
- Padding: P
- Stride: S

**è¾“å‡ºå¤§å°ï¼š**
$$\text{Output} = \frac{W - K + 2P}{S} + 1$$

**å¯è§†åŒ–è¯´æ˜ï¼š**
- ç»¿è‰²åŒºåŸŸè¡¨ç¤ºæ»¤æ³¢å™¨çš„ä½ç½®
- æ­¥é•¿=2 è¡¨ç¤ºæ»¤æ³¢å™¨æ¯æ¬¡ç§»åŠ¨2ä¸ªåƒç´ 
- è¾“å‡ºå°ºå¯¸ä»7Ã—7é™åˆ°3Ã—3

---

### 7. Paddingï¼ˆå¡«å……ï¼‰è¯¦è§£

#### 7.1 å¡«å……çš„å¿…è¦æ€§

![Convolution: Spatial Dimensions - Problem](lec4-9.jpg)
![Convolution: Spatial Dimensions - Problem1](lec4-10.jpg)

**é—®é¢˜ï¼šç‰¹å¾å›¾é€å±‚ç¼©å°ï¼**

**ç¤ºä¾‹ï¼š**
- Input: 7Ã—7
- Filter: 3Ã—3
- Output: 5Ã—5

**ä¸€èˆ¬æƒ…å†µï¼š**
- Input: W
- Filter: K
- Output: $W - K + 1$

**é—®é¢˜åˆ†æï¼š**
- æ²¡æœ‰ padding æ—¶ï¼Œç‰¹å¾å›¾ä¼šä¸æ–­ç¼©å°
- ç»è¿‡å¤šå±‚åï¼Œç©ºé—´ä¿¡æ¯ä¼šå¤§é‡ä¸¢å¤±

#### 7.2 å¡«å……çš„è§£å†³æ–¹æ¡ˆ

**è§£å†³æ–¹æ¡ˆï¼šåœ¨è¾“å…¥å‘¨å›´æ·»åŠ  paddingï¼ˆç”¨0å¡«å……ï¼‰**

**ç¤ºä¾‹ï¼š**
- Input: 7Ã—7
- Filter: 3Ã—3
- **Padding: P**
- Output: $W - K + 1 + 2P$

**"Same" Paddingï¼š**
- ç›®æ ‡ï¼šä¿æŒè¾“å‡ºä¸è¾“å…¥å¤§å°ç›¸åŒ
- å…¬å¼ï¼š$P = (K-1)/2$
- ç¤ºä¾‹ï¼š3Ã—3æ»¤æ³¢å™¨éœ€è¦ padding=1

**å¯è§†åŒ–ï¼š**
```
åŸå§‹ 7Ã—7 â†’ åŠ  padding å˜æˆ 9Ã—9 â†’ å·ç§¯åä»ä¸º 7Ã—7
```

---

### 8. ConvNet æ¶æ„ç¤ºä¾‹

#### 8.1 åŸºæœ¬ConvNetç»“æ„

![Convolution Layer - 1](lec4-7.jpg)
![Convolution Layer - 2](lec4-8.jpg)

**å…¸å‹æ¶æ„ï¼š**

```
è¾“å…¥ (3Ã—32Ã—32)
    â†“
CONV + ReLU (6Ã—28Ã—28)
[6ä¸ª 5Ã—5Ã—3 æ»¤æ³¢å™¨]
    â†“
CONV + ReLU (10Ã—24Ã—24)
[10ä¸ª 5Ã—5Ã—6 æ»¤æ³¢å™¨]
    â†“
CONV + ReLU (ç»§ç»­...)
    â†“
...
```

**å…³é”®ç‰¹ç‚¹ï¼š**
- æ¯ä¸ªå·ç§¯å±‚åè·Ÿ ReLU æ¿€æ´»å‡½æ•°
- é€šé“æ•°é€æ¸å¢åŠ ï¼ˆ3 â†’ 6 â†’ 10 â†’ ...ï¼‰
- ç©ºé—´ç»´åº¦é€æ¸å‡å°ï¼ˆ32 â†’ 28 â†’ 24 â†’ ...ï¼‰

#### 8.2 ç®€åŒ–çš„ConvNetç»“æ„



**ä¸æ˜¾ç¤ºæ¿€æ´»å‡½æ•°çš„æ¶æ„å›¾ï¼š**

```
è¾“å…¥ (3Ã—32Ã—32)
    â†“
CONV (6Ã—28Ã—28)
    â†“
CONV (10Ã—24Ã—24)
    â†“
CONV (ç»§ç»­...)
    â†“
...
```

**è¯´æ˜ï¼š**
- å®é™…ä¸Šæ¯ä¸ª CONV å±‚åéƒ½æœ‰æ¿€æ´»å‡½æ•°
- ä¸ºç®€åŒ–å›¾ç¤ºï¼Œé€šå¸¸ä¸ç”»å‡º

---

### 9. æ± åŒ–å±‚ (Pooling Layers)

#### 9.1 æ± åŒ–å±‚çš„ä½œç”¨

![Pooling Layers: Another way to downsample - Example](lec4-14.jpg)

**æ± åŒ–å±‚ï¼šå¦ä¸€ç§é™é‡‡æ ·æ–¹æ³•**

**Max Pooling ç¤ºä¾‹ï¼š**

**è¾“å…¥ï¼ˆå•ä¸ªæ·±åº¦åˆ‡ç‰‡ï¼‰ï¼š**
```
1  1  2  4
5  6  7  8
3  2  1  0
1  2  3  4
```

**2Ã—2 Max Pooling, stride=2**

**è¾“å‡ºï¼š**
```
6  8
3  4
```

**è¯´æ˜ï¼š**
- æ¯ä¸ª 2Ã—2 åŒºåŸŸå–æœ€å¤§å€¼
- æ­¥é•¿=2ï¼Œä¸é‡å 
- è¾“å‡ºå°ºå¯¸å‡åŠ

**å®Œæ•´è¾“å…¥ï¼š64Ã—224Ã—224**

**å®Œæ•´å¤„ç†ï¼š**
- å¯¹æ¯ä¸ªæ·±åº¦åˆ‡ç‰‡ï¼ˆ64ä¸ªï¼‰ç‹¬ç«‹è¿›è¡Œæ± åŒ–
- è¾“å‡ºï¼š64Ã—112Ã—112

**å…³é”®ç‰¹æ€§ï¼š**
- æä¾›å¯¹å°ç©ºé—´å¹³ç§»çš„ä¸å˜æ€§
- **æ²¡æœ‰å¯å­¦ä¹ å‚æ•°**

#### 9.2 æ± åŒ–å±‚çš„æ•°å­¦æè¿°

![Pooling Summary](lec4-15.jpg)

**è¾“å…¥ï¼š**
- Input: $C \times H \times W$

**è¶…å‚æ•°ï¼š**
1. **Kernel size (æ± åŒ–çª—å£å¤§å°)**ï¼šK
2. **Stride (æ­¥é•¿)**ï¼šS
3. **Pooling function (æ± åŒ–å‡½æ•°)**ï¼šmax æˆ– avg

**è¾“å‡ºå¤§å°ï¼š**
$$H' = \frac{H - K}{S} + 1$$
$$W' = \frac{W - K}{S} + 1$$

- Output size: $C \times H' \times W'$

**å¸¸è§é…ç½®ï¼š**
- **max, K=2, S=2** â†’ äº§ç”Ÿ 2å€é™é‡‡æ ·

**å…³é”®ç‰¹æ€§ï¼š**
- **æ— å¯å­¦ä¹ å‚æ•°**
- é€šé“æ•°ä¸å˜

#### 9.3 æ± åŒ–å±‚çš„å¯è§†åŒ–

![Pooling Layers: Downsampling Visualization](lec4-13.jpg)

**é™é‡‡æ ·è¿‡ç¨‹ï¼š**

```
64Ã—224Ã—224 
    â†“ pool
64Ã—112Ã—112
    â†“ downsampling
   (å¯è§†åŒ–æ˜¾ç¤º)
112Ã—112 è¾“å‡ºå›¾åƒ
```

**å¤„ç†æµç¨‹ï¼š**
1. ç»™å®šè¾“å…¥ $C \times H \times W$
2. å¯¹æ¯ä¸ª $1 \times H \times W$ å¹³é¢è¿›è¡Œé™é‡‡æ ·
3. è¾“å‡ºä¿æŒé€šé“æ•°ä¸å˜

**è¶…å‚æ•°ï¼š**
- Kernel Size
- Stride  
- Pooling function (max/avg)

---

### 10. ä» Transformers çš„æ¼”è¿›

![2021 - Present: Transformers have taken over](lec4-4.jpg)

**æ·±åº¦å­¦ä¹ æ¶æ„çš„æ¼”è¿›ï¼š**

#### 2017: Transformers for language tasks
- **è®ºæ–‡ï¼š** Vaswani et al, "Attention is all you need", NeurIPS 2017
- Transformer æ¶æ„æœ€åˆç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†
- æ ¸å¿ƒæœºåˆ¶ï¼šMulti-Head Attention
- ä½ç½®ç¼–ç  + å‰é¦ˆç½‘ç»œ

#### 2021: Transformers for vision tasks
- **è®ºæ–‡ï¼š** Dosovitskiy et al, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", ICLR 2021
- Vision Transformer (ViT) å°†å›¾åƒåˆ†å‰²æˆ patches
- Patch + Position Embedding
- Transformer Encoder å¤„ç†å›¾åƒåºåˆ—

**é‡è¦è¶‹åŠ¿ï¼š**
- Transformers æ­£åœ¨æ¥ç®¡è®¡ç®—æœºè§†è§‰é¢†åŸŸ
- ä¸å·ç§¯ç½‘ç»œç›¸æ¯”ï¼Œæ›´åŠ çµæ´»å’Œå¼ºå¤§
- ä½†æœ¬è¯¾ç¨‹é‡ç‚¹ä»æ˜¯ ConvNets åŸºç¡€

---

## å…³é”®è¦ç‚¹æ€»ç»“

### 1. å·ç§¯å±‚æ ¸å¿ƒæ¦‚å¿µ

âœ… **å‚æ•°å…±äº«**
- åŒä¸€ä¸ªæ»¤æ³¢å™¨åœ¨æ•´ä¸ªå›¾åƒä¸Šæ»‘åŠ¨
- å¤§å¹…å‡å°‘å‚æ•°é‡

âœ… **å±€éƒ¨è¿æ¥**
- æ¯ä¸ªç¥ç»å…ƒåªçœ‹å±€éƒ¨æ„Ÿå—é‡
- ä¿ç•™ç©ºé—´ç»“æ„ä¿¡æ¯

âœ… **è®¡ç®—å…¬å¼**
$$\text{Output size} = \frac{W - K + 2P}{S} + 1$$

### 2. å¸¸ç”¨é…ç½®æ¨¡å¼

| ç±»å‹ | K | P | S | ä½œç”¨ |
|------|---|---|---|------|
| 3Ã—3 conv | 3 | 1 | 1 | æ ‡å‡†å·ç§¯ |
| 5Ã—5 conv | 5 | 2 | 1 | è¾ƒå¤§æ„Ÿå—é‡ |
| 1Ã—1 conv | 1 | 0 | 1 | é€šé“å˜æ¢ |
| Downsample | 3 | 1 | 2 | é™é‡‡æ ·2å€ |

### 3. æ± åŒ–å±‚ç‰¹ç‚¹

ğŸ”¹ **Max Pooling**ï¼šå–åŒºåŸŸæœ€å¤§å€¼
ğŸ”¹ **Average Pooling**ï¼šå–åŒºåŸŸå¹³å‡å€¼
ğŸ”¹ **å¸¸ç”¨é…ç½®**ï¼š2Ã—2, stride=2ï¼ˆ2å€é™é‡‡æ ·ï¼‰
ğŸ”¹ **æ— å¯å­¦ä¹ å‚æ•°**
ğŸ”¹ **é€šé“æ•°ä¸å˜**

### 4. è®¾è®¡åŸåˆ™

1. **ç©ºé—´ç»´åº¦** â†’ é€å±‚å‡å°
2. **é€šé“æ•°** â†’ é€å±‚å¢åŠ 
3. **ä½¿ç”¨ padding** â†’ é˜²æ­¢ç‰¹å¾å›¾è¿‡å¿«ç¼©å°
4. **æ¿€æ´»å‡½æ•°** â†’ æ¯ä¸ªå·ç§¯å±‚ååŠ  ReLU

---

## ä»£ç å®ç°ç¤ºä¾‹

### å·ç§¯å±‚å‰å‘ä¼ æ’­ï¼ˆNumPyï¼‰

```python
def conv_forward_naive(x, w, b, conv_param):
    """
    å·ç§¯å±‚çš„å‰å‘ä¼ æ’­ï¼ˆæœ´ç´ å®ç°ï¼‰
    
    è¾“å…¥:
    - x: è¾“å…¥æ•°æ® (N, C, H, W)
    - w: æ»¤æ³¢å™¨æƒé‡ (F, C, HH, WW)
    - b: åç½® (F,)
    - conv_param: å­—å…¸ {'stride': S, 'pad': P}
    
    è¾“å‡º:
    - out: è¾“å‡ºæ•°æ® (N, F, H', W')
    """
    N, C, H, W = x.shape
    F, _, HH, WW = w.shape
    stride = conv_param['stride']
    pad = conv_param['pad']
    
    # å¡«å……è¾“å…¥
    x_padded = np.pad(x, ((0,0), (0,0), (pad,pad), (pad,pad)), 
                      mode='constant')
    
    # è®¡ç®—è¾“å‡ºå°ºå¯¸
    H_out = (H + 2*pad - HH) // stride + 1
    W_out = (W + 2*pad - WW) // stride + 1
    
    # åˆå§‹åŒ–è¾“å‡º
    out = np.zeros((N, F, H_out, W_out))
    
    # å·ç§¯æ“ä½œ
    for n in range(N):           # æ¯ä¸ªæ ·æœ¬
        for f in range(F):       # æ¯ä¸ªæ»¤æ³¢å™¨
            for i in range(H_out):
                for j in range(W_out):
                    h_start = i * stride
                    w_start = j * stride
                    
                    # æå–æ„Ÿå—é‡
                    x_slice = x_padded[n, :, 
                                      h_start:h_start+HH,
                                      w_start:w_start+WW]
                    
                    # è®¡ç®— w^T x + b
                    out[n, f, i, j] = np.sum(x_slice * w[f]) + b[f]
    
    return out
```

### Max Pooling å®ç°

```python
def max_pool_forward_naive(x, pool_param):
    """
    Max Pooling å‰å‘ä¼ æ’­
    
    è¾“å…¥:
    - x: è¾“å…¥æ•°æ® (N, C, H, W)
    - pool_param: å­—å…¸ {'pool_height': HH, 'pool_width': WW, 'stride': S}
    
    è¾“å‡º:
    - out: è¾“å‡ºæ•°æ® (N, C, H', W')
    """
    N, C, H, W = x.shape
    HH = pool_param['pool_height']
    WW = pool_param['pool_width']
    stride = pool_param['stride']
    
    # è®¡ç®—è¾“å‡ºå°ºå¯¸
    H_out = (H - HH) // stride + 1
    W_out = (W - WW) // stride + 1
    
    # åˆå§‹åŒ–è¾“å‡º
    out = np.zeros((N, C, H_out, W_out))
    
    # Max pooling
    for n in range(N):
        for c in range(C):
            for i in range(H_out):
                for j in range(W_out):
                    h_start = i * stride
                    w_start = j * stride
                    
                    # æå–æ± åŒ–åŒºåŸŸå¹¶å–æœ€å¤§å€¼
                    pool_region = x[n, c, 
                                  h_start:h_start+HH,
                                  w_start:w_start+WW]
                    out[n, c, i, j] = np.max(pool_region)
    
    return out
```

### PyTorch å®ç°ç¤ºä¾‹

```python
import torch
import torch.nn as nn

class SimpleConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleConvNet, self).__init__()
        
        self.conv_layers = nn.Sequential(
            # Conv1: 3Ã—32Ã—32 â†’ 6Ã—28Ã—28
            nn.Conv2d(3, 6, kernel_size=5),
            nn.ReLU(),
            
            # Conv2: 6Ã—28Ã—28 â†’ 10Ã—24Ã—24
            nn.Conv2d(6, 10, kernel_size=5),
            nn.ReLU(),
            
            # Pool: 10Ã—24Ã—24 â†’ 10Ã—12Ã—12
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        self.fc_layers = nn.Sequential(
            nn.Linear(10 * 12 * 12, 100),
            nn.ReLU(),
            nn.Linear(100, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.fc_layers(x)
        return x

# ä½¿ç”¨ç¤ºä¾‹
model = SimpleConvNet(num_classes=10)
input_tensor = torch.randn(1, 3, 32, 32)
output = model(input_tensor)
print(f"Output shape: {output.shape}")  # [1, 10]
```
